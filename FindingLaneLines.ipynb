{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads in the image to 'image'\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "\n",
    "#Printing out some stats and plotting image\n",
    "print('Image dimensions:', image.shape)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from 'vertices'. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #Filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #Returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=4):\n",
    "    \"\"\"\n",
    "    This function draws 'lines' onto 'img' with 'color' and 'thickness'.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"Returns an image with Hough lines drawn.\"\"\"\n",
    "    \n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    \n",
    "    \"\"\"Use following code for outputting raw lane lines:\"\"\"\n",
    "    #line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    #draw_lines(line_img, lines)\n",
    "    #return line_img\n",
    "    \n",
    "    \"\"\"For full lane lines, return lines for extrapolating function\"\"\"\n",
    "    return lines\n",
    "    \n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    Adds \"img\" to \"initial image\"\n",
    "    The result image is computed as follows:\n",
    "    initial_img * α + img * β + γ\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "def extrapolate_lines(lines):\n",
    "    \"\"\"\n",
    "    Extrapolates lines from Hough transform to full lane lines.\n",
    "    Code on solution from Matt Hardwick on Medium\n",
    "    Expects lines, not a full image!\n",
    "    When sorting according to the slope, we have to take into account that\n",
    "    the y axis grows in the opposite direction than in a conventional coordinate system.\n",
    "    Therefore:\n",
    "    Positive slope -> right line\n",
    "    Negative slope -> right line\n",
    "    \"\"\"\n",
    "    \n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            \n",
    "            if math.fabs(slope) < 0.5: # <-- Only consider extreme slope\n",
    "                continue\n",
    "\n",
    "            if slope <= 0:\n",
    "                left_line_x.extend([x1, x2])\n",
    "                left_line_y.extend([y1, y2])\n",
    "            else:\n",
    "                right_line_x.extend([x1, x2])\n",
    "                right_line_y.extend([y1, y2])\n",
    "                \n",
    "    #Set fixed value for start and end point on y axis\"\n",
    "    min_y = 320 # <-- Just below the horizon\n",
    "    max_y = 540 # <-- The bottom of the image\n",
    "    \n",
    "    #Linear fitting using the grouped Hough lines, returns an object that represents x = m*y + b\n",
    "    fit_left = np.poly1d(np.polyfit(\n",
    "        left_line_y,\n",
    "        left_line_x,\n",
    "        deg=1\n",
    "    ))\n",
    "    \n",
    "    fit_right = np.poly1d(np.polyfit(\n",
    "        right_line_y,\n",
    "        right_line_x,\n",
    "        deg=1\n",
    "    ))\n",
    "    \n",
    "    #Find start and end \"x\" values using linear equation\n",
    "    \n",
    "    left_x0 = int(fit_left(max_y))\n",
    "    left_x1 = int(fit_left(min_y))\n",
    "    \n",
    "    right_x0 = int(fit_right(max_y))\n",
    "    right_x1 = int(fit_right(min_y))\n",
    "    \n",
    "    #Draw lines onto a black image\n",
    "    \n",
    "    full_lines = np.zeros((540, 960, 3), dtype=np.uint8)\n",
    "    draw_lines(\n",
    "        full_lines,\n",
    "        [[\n",
    "            [left_x0, max_y, left_x1, min_y],\n",
    "            [right_x0, max_y, right_x1, min_y],\n",
    "        ]],\n",
    "            thickness=8,\n",
    "    )\n",
    "\n",
    "    return full_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    Complete pipeline for processing images.\n",
    "    Takes raw colored images, outputs the image with lane lines indicated with straight red lines\n",
    "    Contains commented imshow functions for each step for debugging / image plotting purposes.\n",
    "    Raw lane lines can also be generated by uncommenting the relevant sections.\n",
    "    (In this case however, the hough lines function also needs to be modified.)\n",
    "    \"\"\"\n",
    "\n",
    "    gray = grayscale(image)\n",
    "    #plt.imshow(gray, cmap='gray')\n",
    "           \n",
    "    blurred = gaussian_blur(gray, 3)\n",
    "    #plt.imshow(blurred, cmap='gray')\n",
    "           \n",
    "    edges = canny(blurred, 50, 150)\n",
    "    #plt.imshow(edges, cmap='gray')\n",
    "\n",
    "    vertices = np.array([[(90,540) , (450, 325), (520, 325), (940,540)]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "    #plt.imshow(masked_edges, cmap='gray')\n",
    "\n",
    "    raw_lane_lines = hough_lines(masked_edges, 4, np.pi/60, 60, 100, 100)\n",
    "    #plt.imshow(raw_lane_lines, cmap='gray')\n",
    "    \n",
    "    full_lane_lines = extrapolate_lines(raw_lane_lines)\n",
    "    #plt.imshow(full_lane_lines, cmap='gray')\n",
    "\n",
    "    #result_raw = weighted_img(raw_lane_lines, image, α=0.8, β=1., γ=0.)\n",
    "    #plt.imshow(result_raw)\n",
    "    \n",
    "    result_full = weighted_img(full_lane_lines, image, α=0.8, β=1., γ=0.)\n",
    "    #plt.imshow(result_full, cmap='gray')\n",
    "    \n",
    "    #return result_raw\n",
    "    return result_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline applied to the example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_image = process_image(image)\n",
    "plt.imshow(annotated_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline applied to the videos\n",
    "Code uses fl_image function of VideoClip class to apply pipeline to the test videos.\n",
    "\n",
    "Output is the annotated video with lane lines indicated by straight red lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,3) <--- For testing\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "#clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,3) <--- For testing\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
